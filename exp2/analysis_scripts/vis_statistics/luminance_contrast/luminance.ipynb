{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d213eaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path as op\n",
    "import glob\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a80ec11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread, imshow\n",
    "from skimage import data\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.filters.rank import entropy\n",
    "from skimage.morphology import disk\n",
    "from skimage.color import rgb2hsv, rgb2gray, rgb2yuv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1246bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "maindir = '/Users/ShariLiu/Dropbox (MIT)/Research/Studies/_NIRS/NES/exp2/analysis_scripts/vis_statistics'\n",
    "#videos = glob.glob(op.join(maindir, 'videos/*.mp4'))\n",
    "videos = glob.glob(op.join(maindir, 'stills/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5131002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ShariLiu/Dropbox (MIT)/Research/Studies/_NIRS/NES/exp2/analysis_scripts/vis_statistics/stills/physics_support-exp1_ball_unexp'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = videos[1]\n",
    "nameofx = op.basename(x).split('.mp4')[0]\n",
    "op.join(maindir, 'stills', nameofx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7303fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current video: physics_support-exp1_ball_fam\n",
      "current video: physics_support-exp1_ball_unexp\n",
      "current video: physics_support-exp1_ball_exp\n"
     ]
    }
   ],
   "source": [
    "# INITIALIZE OUTPUT DATAFRAMES \n",
    "all_videos_df = pd.DataFrame()\n",
    "contr_all_videos_df = pd.DataFrame()\n",
    "\n",
    "# luminance calculated following iCatcher+ visualize.py function 'sample_luminance': \n",
    "# https://github.com/yoterel/icatcher_plus/blob/a52a3ecb5d02de94098f6c1a22d724885db66dcb/visualize.py\n",
    "\n",
    "for vI in range(len(videos)):\n",
    "    # INITIALIZE VECTORS FOR EACH VIDEO\n",
    "    lum_means = [];\n",
    "    contrasts = [];\n",
    "\n",
    "    # LOAD VIDEO AND SPLIT FILENAME INTO COND INFO\n",
    "    videofile = videos[vI];\n",
    "    video_name = op.basename(videofile).split('.mp4')[0]\n",
    "    stillpath = op.join(maindir, 'stills', video_name)\n",
    "    stills = glob.glob(op.join(stillpath, '*.jpg'))\n",
    "    name_parts = video_name.split('_')\n",
    "    \n",
    "    # GET APPROPRIATE COND NAMES ------------------------------------------------------------------\n",
    "\n",
    "    domain = name_parts[0]\n",
    "    scenario_group = name_parts[1]\n",
    "    scenario_specific = name_parts[2]\n",
    "    event = name_parts[3]\n",
    "\n",
    "    print('current video: ' + video_name)\n",
    "\n",
    "    # for each frame in this video.. \n",
    "    for imI in range(0, len(stills), 2):\n",
    "        \n",
    "        # open the video \n",
    "        im = Image.open(stills[imI])\n",
    "        # split into R-G-B\n",
    "        imsplit = Image.Image.split(im)\n",
    "        r = np.array(imsplit[0])\n",
    "        g = np.array(imsplit[1])\n",
    "        b = np.array(imsplit[2])\n",
    "        \n",
    "        # ----- LUMINANCE -----\n",
    "        b = (b / 255) ** 2.2\n",
    "        g = (g / 255) ** 2.2\n",
    "        r = (r / 255) ** 2.2\n",
    "        lum_image = 0.2126 * r + 0.7152 * g + 0.0722 * b\n",
    "        \n",
    "        # ------ CONTRAST ON GREYSCALE IMG ----- \n",
    "        skimg_grey = rgb2gray(imread(stills[imI]))\n",
    "        contrast_arr = np.ravel(np.array(skimg_grey))\n",
    "        iqr_contrast = stats.iqr(contrast_arr)\n",
    "        luminance_out = np.mean(lum_image)\n",
    "        \n",
    "        # append to list per-video\n",
    "        lum_means.append([domain, scenario_group, scenario_specific, event, stills[imI].split('frame_')[1].split('.jpg')[0], luminance_out])\n",
    "        contrasts.append([domain, scenario_group, scenario_specific, event, stills[imI].split('frame_')[1].split('.jpg')[0], iqr_contrast])\n",
    "        \n",
    "        # close image\n",
    "        im.close()\n",
    "        \n",
    "        #entropy_img = entropy(skimg_grey, disk(5))\n",
    "        #entropy_list.append([domain, task_specific, scenario_string, event, stills[imI].split('frame_')[1].split('.jpg')[0], np.mean(entropy_img)])\n",
    "    \n",
    "    # save per video files for frame-wise luminance, contrast\n",
    "    outpath_lum_means = 'outputs/luminance_perframe_' + video_name + '.csv'\n",
    "    lum_means_df = pd.DataFrame(lum_means, columns=\n",
    "                                ['domain', 'scenario_group', 'scenario_specific', 'event','frame_num', 'mean_luminance'])\n",
    "    lum_means_df.to_csv(outpath_lum_means, index=False) \n",
    "    \n",
    "    outpath_contrasts = 'outputs/contrast_perframe_' + video_name + '.csv'\n",
    "    contrasts_df = pd.DataFrame(contrasts, columns=\n",
    "                                ['domain', 'scenario_group', 'scenario_specific', 'event','frame_num', 'iqr_contrast'])\n",
    "    contrasts_df.to_csv(outpath_contrasts, index=False)\n",
    "    \n",
    "    # get mean across frames \n",
    "    video_mean_luminance = np.mean(lum_means_df['mean_luminance'])\n",
    "    video_mean_iqr_contrast = np.mean(contrasts_df['iqr_contrast'])\n",
    "    \n",
    " \n",
    " # save out per video mean contrast/luminance  \n",
    "    vidmean_df = pd.DataFrame({\n",
    "        'domain': domain,\n",
    "        'scenario_group': scenario_group, \n",
    "        'scenario_specific': scenario_specific, \n",
    "        'event': event,\n",
    "        'video': video_name, \n",
    "        'mean_luminance': video_mean_luminance}, index=[0])\n",
    "    all_videos_df = all_videos_df.append(vidmean_df)\n",
    "    \n",
    "    \n",
    "    vidmean_df_contr = pd.DataFrame({\n",
    "        'domain': domain,\n",
    "        'scenario_group': scenario_group, \n",
    "        'scenario_specific': scenario_specific, \n",
    "        'event': event,\n",
    "        'video': video_name, \n",
    "        'iqr_contrast': video_mean_iqr_contrast}, index=[0])\n",
    "    contr_all_videos_df = contr_all_videos_df.append(vidmean_df_contr)\n",
    "# all_videos_df.to_csv('outputs/LUMINANCE_ALL_VIDEOS.csv', index=False)\n",
    "# contr_all_videos_df.to_csv('outputs/CONTRAST_ALL_VIDEOS.csv', index=False)\n",
    "\n",
    "all_videos_df.to_csv('outputs/LUMINANCE_SUPPORT.csv', index=False)\n",
    "contr_all_videos_df.to_csv('outputs/CONTRAST_SUPPORT.csv', index=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9f8df76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043e7f58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
